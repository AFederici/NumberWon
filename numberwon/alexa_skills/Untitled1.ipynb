{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(str(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3610208034515381\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "import sys\n",
    "sys.path.insert(0, \"C:/Users/User/Desktop/beaver/NumberWon/numberwon/alexa_skills/profiles/Profiles\")\n",
    "from Profile import Profile\n",
    "from UserDatabase import UserDatabase\n",
    "\n",
    "sys.path.insert(0, \"C:/Users/User/Desktop/beaver/NumberWon/numberwon/alexa_skills\")\n",
    "from fanfiction import Fanfiction\n",
    "\n",
    "f = Fanfiction()\n",
    "term = \"hunger games\"\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.23454213142395\n"
     ]
    }
   ],
   "source": [
    "t3 = time.time()\n",
    "text = f.find_fanfiction(term)\n",
    "\n",
    "# for key, val in text.items():\n",
    "#     a = open(term + '_test.txt', 'w')\n",
    "#     a.write(val)\n",
    "#     a.close()\n",
    "t4 = time.time()\n",
    "print(t4-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What?\n",
      "\n",
      "Did I really just hear…?\n",
      "\n",
      "Doris does the honors of turning on the television. \"Ooh, this is so\n",
      "exciting!\" she exclaims. “Remember how she murdered _six_ tributes, she never\n",
      "\n",
      "\n",
      "1.7420132160186768\n",
      "What?\n",
      "\n",
      "Did I really just hear…?\n",
      "\n",
      "Doris does the honors of turning on the television. \"Ooh, this is so\n",
      "exciting!\" she exclaims.\n"
     ]
    }
   ],
   "source": [
    "t5 = time.time()\n",
    "import html2text\n",
    "# with open(term + \"_test.txt\", \"r\") as z:\n",
    "#     t = z.read()\n",
    "#print(type(t))\n",
    "#term = \"harry potter\"\n",
    "text[term] = str(text[term])\n",
    "lm = f.train_lm(text[term], 13)\n",
    "f.text = f.generate_text(lm, 13, nletters=200)\n",
    "f.text = html2text.html2text(f.text)\n",
    "print(f.text)\n",
    "\n",
    "a = open(term + '.txt', 'w')\n",
    "a.write(f.text)\n",
    "a.close()\n",
    "t6 = time.time()\n",
    "print(t6-t5)\n",
    "\n",
    "#html2text.html2text(f.text)\n",
    "print(f.text[:f.text.rfind(\".\")+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for x in tuple([1, 2]):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "gender = \"female\"\n",
    "name_set = \"us\"\n",
    "country = \"us\"\n",
    "site = \"http://www.fakenamegenerator.com\"\n",
    "hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "req = Request(site, headers=hdr)\n",
    "page = urlopen(req)\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "option = soup.find_all(\"option\")\n",
    "\n",
    "#print(\"\\n\".join([option[n].text for n, val in enumerate(option)]))\n",
    "soup.find_all(\"li\", \"lab\")\n",
    "c = soup.find(\"select\", {\"id\": \"c\"})\n",
    "#print(\"ctype\", type(c))\n",
    "gen = soup.find(\"select\", {\"id\": \"gen\"})\n",
    "gender_name = \"female\"\n",
    "l = [\"gen\", \"n\", \"c\"]\n",
    "v = dict()\n",
    "for ele in l:\n",
    "    \"\"\"Parameters:\n",
    "    -------------------------\n",
    "        key: id\n",
    "        returns: problem\"\"\"\n",
    "    link_option = soup.find(\"select\", {\"id\": ele}).find_all(\"option\")\n",
    "    option_value = [opt[\"value\"] for opt in link_option if gender_name.lower() == opt.text.lower()] #to be inputted into url\n",
    "    #session.attributes[\"Gender\"] = option_value[0]\n",
    "    #session.attributes[\"gen\"] = [* soup.find_all(\"option\").text if gender_name in \n",
    "    value = [x.text for x in link_option]\n",
    "    v[ele] = \"\\n\".join(value) #splits page into gender, name_set, country options\n",
    "    \n",
    "# #iterate through v to get options to display in Alexa Card\n",
    "\n",
    "\n",
    "# option[5].text\n",
    "# print([opt[\"value\"] for opt in option if gender_name == opt.text.lower()])\n",
    "\n",
    "\n",
    "print(type(v[\"gen\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jimmie J. Baily'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding_name = soup.find_all(\"div\", \"content\")\n",
    "soup.find(attrs = {\"class\": \"info\", \"class\": \"address\"}).find(\"h3\").text\n",
    "#[ele.text for ele in finding_name if ele.find_all(\"info\") != None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('megan', <profiles.Profiles.Profile.Profile object at 0x000000000769E5C0>)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/User/Desktop/beaver/NumberWon/numberwon/alexa_skills/profiles/Profiles')\n",
    "from Profile import Profile\n",
    "from UserDatabase import UserDatabase\n",
    "\n",
    "alexa_path = 'C:/Users/User/Desktop/beaver/NumberWon/numberwon/alexa_skills/profiles'\n",
    "#sys.path.insert(0, alexa_path)\n",
    "#every Fanfiction instance saves a text file into of top fanfiction for a term\n",
    "#iterates through all the databases and saves txt files based on preferences\n",
    "import os\n",
    "save_path = 'C:/Users/User/Desktop/beaver/NumberWon/numberwon/alexa_skills/fanfiction_files'\n",
    "import itertools\n",
    "\n",
    "f = Fanfiction()\n",
    "together = list()\n",
    "for f in os.listdir(alexa_path):\n",
    "    if f.endswith(\".npy\"):\n",
    "        #print(f)\n",
    "        d = UserDatabase(alexa_path+\"/\"+f)\n",
    "        print(d)\n",
    "        #find all keys that have fan in them\n",
    "        #l = print([type(val) for key, val in d.dict.items()])\n",
    "        profiles = [val2 for key, val in d.dict.items() for key1, val2 in val.pref_dict.items() if \"fan\" in key1]\n",
    "        #print(profiles)\n",
    "        together.extend(itertools.chain.from_iterable(profiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['harry potter']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomlist = []\n",
    "len(randomlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.attributes[\"Current_User\"] = session.attributes[\"Current_User\"].lower()\n",
    "p = d.dict[session.attributes[\"Current_User\"]]\n",
    "listing = tuple(p.get_preferences_by_user(session.attributes[\"Current_User\"], key) for key, val in p.pref_dict if \"fan\" in key)\n",
    "listing = itertools.chain.from_iterable(listing)\n",
    "print(\"preferences: \", listing)\n",
    "content = \"\"\n",
    "\n",
    "for term in listing:\n",
    "    with open(\"fanfiction_files/\" + str(term) + \".txt\", \"r\", 'cp1252') as z:\n",
    "        value = str(z.read())\n",
    "        lm = f.train_lm(value, 13)\n",
    "        text = html2text.html2text(f.generate_text(lm, 13, number))\n",
    "        text = text[:text.rfind(\".\") + 1]\n",
    "        content += term.title() + 'Fanfiction: \\n' + value + \"\\n\\n\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
